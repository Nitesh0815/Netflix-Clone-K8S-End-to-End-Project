name: '🔨 Terraform + Ansible Automation on AWS'

on:
  workflow_dispatch:
    inputs:
      action:
        type: choice
        description: 'Select Terraform Action'
        options:
          - plan
          - apply
          - destroy
        required: true
        default: 'plan'

env:
  # Secrets for Terraform Cloud Backend
  TF_API_TOKEN: ${{ secrets.TF_API_TOKEN }}
  TF_WORKSPACE: ${{ secrets.TF_WORKSPACE }}
  TF_CLOUD_ORGANIZATION: ${{ secrets.TF_CLOUD_ORGANIZATION }}
  # Secrets for AWS Provider
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  # CRITICAL ADDITION: Pass AWS Key Pair name to Terraform via TF_VAR
  TF_VAR_ssh_key_name: ${{ secrets.AWS_KEY_PAIR_NAME }}

permissions:
  contents: read

jobs:
  terraform:
    name: Terraform ${{ github.event.inputs.action }}
    runs-on: ubuntu-latest

    defaults:
      run:
        shell: bash
        # Assuming your Terraform files are in a subdirectory named 'Terraform'
        working-directory: Terraform

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v5

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          # Using the requested version 1.7.5
          terraform_version: "1.7.5" 
          cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

      - name: Terraform Init
        run: terraform init

      - name: Terraform Validate
        run: terraform validate

      - name: Terraform Plan
        if: ${{ github.event.inputs.action == 'plan' }}
        run: terraform plan -input=false

      - name: Terraform Apply
        if: ${{ github.event.inputs.action == 'apply' }}
        run: terraform apply -auto-approve

      - name: Terraform Destroy
        if: ${{ github.event.inputs.action == 'destroy' }}
        run: terraform destroy -auto-approve

      # 🔑 CRITICAL: Set up SSH Key for Ansible Connectivity
      - name: Setup SSH Agent
        if: ${{ github.event.inputs.action == 'apply' }}
        uses: webfactory/ssh-agent@v0.9.0
        with:
          # This secret MUST contain the private key used to launch the EC2 instances
          ssh-private-key: ${{ secrets.ANSIBLE_SSH_PRIVATE_KEY }}

      # 🔧 Run Ansible after Terraform Apply
      - name: Run Ansible Playbook
        if: ${{ github.event.inputs.action == 'apply' }}
        run: |
          echo "🟢 Installing Ansible and jq..."
          sudo apt update -y
          sudo apt install -y ansible python3 jq

          # 2. FIX: We stay in the 'Terraform' directory to run 'terraform output'
          echo "📦 Collecting Terraform Outputs..."
          # Output is written one directory up into the 'ansible' folder
          terraform output -json > ../ansible/ec2_ips.json

          echo "⚙️ Generating Dynamic Inventory..."
          cd ../ansible # Move to repo_root/ansible to run the playbook

          ls -l # Debug: verify ec2_ips.json exists

          # === DEBUGGING ADDITIONS START HERE ===
          echo "DEBUG: Raw contents of ec2_ips.json:"
          cat ec2_ips.json
          echo "======================================"

          # Extract IPs from Terraform JSON output
          JENKINS_IP=$(jq -r '.jenkins_server_ip.value' ec2_ips.json)
          MONITORING_IP=$(jq -r '.monitoring_server_ip.value' ec2_ips.json)
          MASTER_IP=$(jq -r '.k8s_master_ip.value' ec2_ips.json)

          echo "DEBUG: Extracted JENKINS_IP: $JENKINS_IP"
          echo "DEBUG: Extracted MONITORING_IP: $MONITORING_IP"
          echo "DEBUG: Extracted MASTER_IP: $MASTER_IP"
          echo "======================================"
          # === DEBUGGING ADDITIONS END HERE ===

          # Create a hosts file using printf to avoid YAML parser errors
          echo "" > inventory.ini # Clear the file
          printf "[jenkins]\n" >> inventory.ini
          # Check for null values and handle them gracefully (though they should be valid IPs)
          if [ -z "$JENKINS_IP" ] || [ "$JENKINS_IP" == "null" ]; then
            echo "Error: Jenkins IP is missing or null."
            exit 1
          fi
          printf "%s ansible_user=ec2-user\n\n" "$JENKINS_IP" >> inventory.ini
          
          printf "[monitoring]\n" >> inventory.ini
          printf "%s ansible_user=ec2-user\n\n" "$MONITORING_IP" >> inventory.ini
          
          printf "[kubernetes_master]\n" >> inventory.ini
          printf "%s ansible_user=ec2-user\n\n" "$MASTER_IP" >> inventory.ini
          
          printf "[all:vars]\n" >> inventory.ini
          printf "ansible_ssh_common_args='-o StrictHostKeyChecking=no'\n" >> inventory.ini

          echo "✅ Inventory file created:"
          cat inventory.ini
          
          # Optional: Add a brief pause to allow EC2 instances to fully initialize SSH
          echo "😴 Waiting 60 seconds for EC2 instances to become fully reachable..."
          sleep 60
          
          echo "🚀 Running Ansible Playbook with wait_for_connection..."
          # Ensure the instance is up and ready for SSH before running the main playbook.
          ansible all -i inventory.ini -m wait_for_connection -a "delay=5 timeout=300"
          
          echo "✅ SSH Connection Established. Running site.yml..."
          ansible-playbook -i inventory.ini site.yml
