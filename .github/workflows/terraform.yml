name: 'üî® Terraform + Ansible Automation on AWS'

on:
  workflow_dispatch:
    inputs:
      action:
        type: choice
        description: 'Select Terraform Action'
        options:
          - plan
          - apply
          - destroy
        required: true
        default: 'plan'

env:
  # Secrets for Terraform Cloud Backend
  TF_API_TOKEN: ${{ secrets.TF_API_TOKEN }}
  TF_WORKSPACE: ${{ secrets.TF_WORKSPACE }}
  TF_CLOUD_ORGANIZATION: ${{ secrets.TF_CLOUD_ORGANIZATION }}
  # Secrets for AWS Provider
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
  # Pass Key Pair Name to Terraform using TF_VAR_ prefix
  # This matches your Terraform variable 'ssh_key_name'
  TF_VAR_ssh_key_name: ${{ secrets.AWS_KEY_PAIR_NAME }}

permissions:
  contents: read

jobs:
  terraform:
    name: Terraform ${{ github.event.inputs.action }}
    runs-on: ubuntu-latest

    defaults:
      run:
        shell: bash
        # Assuming your Terraform files are in a subdirectory named 'Terraform'
        working-directory: Terraform

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v5

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          # Using the requested version 1.7.5
          terraform_version: "1.7.5" 
          cli_config_credentials_token: ${{ secrets.TF_API_TOKEN }}

      - name: Terraform Init
        run: terraform init

      - name: Terraform Validate
        run: terraform validate

      - name: Terraform Plan
        if: ${{ github.event.inputs.action == 'plan' }}
        run: terraform plan -input=false

      - name: Terraform Apply
        if: ${{ github.event.inputs.action == 'apply' }}
        run: terraform apply -auto-approve

      - name: Terraform Destroy
        if: ${{ github.event.inputs.action == 'destroy' }}
        run: terraform destroy -auto-approve

      # üîë CRITICAL: Set up SSH Key for Ansible Connectivity
      - name: Setup SSH Agent
        if: ${{ github.event.inputs.action == 'apply' }}
        uses: webfactory/ssh-agent@v0.9.0
        with:
          # This secret MUST contain the private key used to launch the EC2 instances
          ssh-private-key: ${{ secrets.ANSIBLE_SSH_PRIVATE_KEY }}

      # üîß Run Ansible after Terraform Apply
      - name: Run Ansible Playbook
        if: ${{ github.event.inputs.action == 'apply' }}
        run: |
          echo "üü¢ Installing Ansible, jq, and Python dependencies..."
          sudo apt update -y
          # Install dependencies required for Ansible and the Python script
          sudo apt install -y ansible python3 jq python3-pip
          pip3 install --user jinja2

          # The job starts in the 'Terraform' directory.
          
          echo "üì¶ Collecting Terraform Outputs..."
          # Write output to the repo's ansible folder, one level up
          terraform output -json > ../ansible/ec2_ips.json

          echo "‚öôÔ∏è Generating Dynamic Inventory..."
          # Change directory to the Ansible folder
          cd ../ansible
          
          # üêõ DEBUG CHANGE: List contents of the 'scripts' directory to confirm the file exists
          echo "Listing contents of 'scripts/' directory:"
          ls -l scripts/ 

          # Execute the Python script (ansible/scripts/inventory_generator.py)
          python3 scripts/inventory_generator.py ec2_ips.json inventory.ini 

          echo "‚úÖ Inventory file created:"
          cat inventory.ini
          
          echo "üò¥ Waiting 60 seconds for EC2 instances to become fully reachable..."
          sleep 60
          
          echo "üöÄ Running Ansible Playbook with wait_for_connection..."
          # Use -u ubuntu for the connection user, as configured in the Python script.
          ansible all -i inventory.ini -u ubuntu -m wait_for_connection -a "delay=5 timeout=300"
          
          echo "‚úÖ SSH Connection Established. Running site.yml..."
          ansible-playbook -i inventory.ini -u ubuntu site.yml
